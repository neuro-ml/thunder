{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>You saw the lightning. Now it's time to hear the thunder</p>"},{"location":"#thunder","title":"Thunder","text":"<p>The Deep Learning framework based on Lightning.</p>"},{"location":"#installation","title":"Installation","text":"<p>You can install from pypi <pre><code>pip install thunder\n</code></pre> or directly from GitHub <pre><code>git clone https://github.com/neuro-ml/thunder.git\ncd thunder &amp;&amp; pip install -e .\n</code></pre></p>"},{"location":"#start-experimenting","title":"Start experimenting","text":"<p>It's as simple as 1, 2, 3:</p> <ol> <li> <p>Create a config (e.g. <code>base.config</code>):     <pre><code>from myproject import MyDataset, MyModule\nfrom lightning import Trainer\nfrom torch.utils.data import DataLoader\n# these 3 fields are required\ntrain_data = DataLoader(MyDataset())\nmodule = MyModule()\ntrainer = Trainer()\n</code></pre></p> </li> <li> <p>Build the experiment:     <pre><code>thunder build base.config /path/to/some/folder\n</code></pre></p> </li> <li> <p>Run it     <pre><code>thunder run /path/to/some/folder\n</code></pre></p> </li> </ol> <p>Also, 2 and 3 can be combined into a single command: <pre><code>thunder build-run base.config /path/to/some/folder\n</code></pre></p>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#thundermodule","title":"ThunderModule","text":""},{"location":"#metriclogger","title":"MetricLogger","text":""},{"location":"#experiment-configs","title":"Experiment configs","text":""},{"location":"#cli-integrations-with-wandb","title":"CLI &amp; Integrations with WandB","text":""},{"location":"callbacks/","title":"Callbacks","text":"<p>Lightning Callbacks allow you to modify your training pipelines. For extra information see this.</p>"},{"location":"callbacks/#thunder-callbacks","title":"Thunder Callbacks","text":"Name Description MetricLogger Computes metrics and logs them TimeProfiler Logs the time of each LightningModule's step FailOnInterrupt Forces lightning Trainer to fail on KeyboardInterrupt"},{"location":"callbacks/fail_on_interrupt/","title":"FailOnInterrupt","text":"<p>Forces lightning Trainer to fail on KeyboardInterrupt by raising RuntimeError.</p>"},{"location":"callbacks/fail_on_interrupt/#usage","title":"Usage","text":"<pre><code>from lightning import Trainer\nfrom thunder.callbacks import FailOnInterrupt\ntrainer = Trainer(..., callbacks=[FailOnInterrupt()])\n</code></pre>"},{"location":"callbacks/fail_on_interrupt/#reference","title":"Reference","text":""},{"location":"callbacks/fail_on_interrupt/#thunder.callbacks.fail_on_interrupt.FailOnInterrupt","title":"thunder.callbacks.fail_on_interrupt.FailOnInterrupt","text":"<p>Forces RuntimeError in order for trainer to stop if KeyboardInterrupt was raised</p>"},{"location":"callbacks/fail_on_interrupt/#thunder.callbacks.fail_on_interrupt.FailOnInterrupt.on_exception","title":"on_exception","text":"<pre><code>on_exception(trainer: Trainer, pl_module: LightningModule, exception: BaseException) -&gt; None\n</code></pre> Source code in <code>thunder/callbacks/fail_on_interrupt.py</code> <pre><code>def on_exception(self, trainer: Trainer, pl_module: LightningModule, exception: BaseException) -&gt; None:\nif isinstance(exception, KeyboardInterrupt):\nraise RuntimeError(\"Finished run on KeyboardInterrupt\") from exception\n</code></pre>"},{"location":"callbacks/metric_logger/","title":"MetricLogger","text":"<p>This callback takes on computation and aggregation of the specified metrics.  </p>"},{"location":"callbacks/metric_logger/#usage","title":"Usage","text":""},{"location":"callbacks/metric_logger/#loss","title":"Loss","text":"<p>Despite the word <code>Metric</code> in the name, this callback also takes on logging of train loss(es). It casts them by the following rules: - If <code>loss</code> is of type <code>torch.Tensor</code> - <code>{\"loss\": loss}</code> is logged. - If <code>loss</code> is a list or tuple, then it is logged as <code>{\"i\": loss_i}</code>. - If <code>loss</code> is a dict, then it is logged as is.  </p> <p> </p> <p>All Tensors are cast to numpy arrays.</p> <p>At the end of epoch they are averaged and sent to logger.</p>"},{"location":"callbacks/metric_logger/#metric-computation","title":"Metric Computation","text":"<p>Metrics are assumed to be received as tuple <code>(X, Y)</code>, where X - batch of predictions, Y - batch of targets.  Further process of computation depends on whether <code>Group</code> or <code>Single</code> metrics are used. Also, there is no difference for MetricLogger between  <code>(X, Y)</code> and <code>((X,), (Y,))</code>. If your model has multiple outputs or requires multiple targets (e.g. neural network with 2 heads.), the output is expected to be <code>((X1, X2), (Y1, Y2))</code> (the most common way to represent such data in PyTorch), where X1 is batch of model's first output. In this case outputs will be recombined, so the first object of the output will be <code>((x1, x2), (y1, y2))</code>, where x1 is the first element of batch <code>X1</code>.  </p> <p> </p> <p>Inside the callback outputs are swapped, so if LightningModule returns (X, Y) then metrics will receive (Y, X).</p>"},{"location":"callbacks/metric_logger/#group-metrics","title":"Group metrics","text":"<p>Group metrics are computed on the entire dataset. For example, you want to compute classification accuracy on MNIST. <pre><code>from thunder.callbacks import MetricLogger\nfrom sklearn.metrics import accuracy_score\ntrainer = Trainer(callbacks=[MetricLogger(group_metrics={\"accuracy\": accuracy_score})])\n</code></pre></p> <p>If you use any loggers (e.g. <code>Tensorboard</code> or <code>WandB</code>), <code>accuracy</code> will appear in them as follows: <code>val/accuracy</code> - validation metrics. <code>test/accuracy</code> - test metrics.</p> <p>You can also use preprocessing functions as keys of the dictionary. It is  covered in Preprocessing part in Single Metrics paragraph.</p>"},{"location":"callbacks/metric_logger/#single-metrics","title":"Single metrics","text":"<p>Single metrics are computed on each object separately and only then aggregated. It is a common use case for tasks like segmentation or object detection.</p>"},{"location":"callbacks/metric_logger/#simple-use-case","title":"Simple use case","text":"<p><pre><code>from thunder.callbacks import MetricLogger\nfrom sklearn.metrics import accuracy_score\ntrainer = Trainer(callbacks=[MetricLogger(single_metrics={\"accuracy\": accuracy_score})])\n</code></pre> MetricLogger will log mean values by default. But you can add custom aggregations as well.</p>"},{"location":"callbacks/metric_logger/#custom-aggregations","title":"Custom aggregations","text":"<p>Let see what can be done if we want to log <code>std</code> of metrics as well as mean values. <pre><code>import numpy as np\nfrom thunder.callbacks import MetricLogger\nfrom sklearn.metrics import accuracy_score\naggregate_fn = np.std\nmetric_logger = MetricLogger(single_metrics={\"accuracy\": accuracy_score},\naggregate_fn=aggregate_fn) \ntrainer = Trainer(callbacks=[metric_logger])\n</code></pre> The mean values appear in loggers with no additional keys.  MetricCallback will try to infer the name of an aggregating function and use it as an additional key.</p> <p><code>val/accuracy</code> - validation mean accuracy. <code>val/std/accuracy</code> - validation accuracy std. <code>test/accuracy</code> - test mean accuracy. <code>test/std/accuracy</code> - test accuracy std.</p> <p><code>aggregate_fn</code> can also be specified as follows:</p> <p><pre><code>import numpy as np\naggregate_fn = [np.std, np.median]\naggregate_fn = [np.std, \"median\", \"max\", \"min\"]\naggregate_fn = {\"zero\": lambda x: x[0]}\n</code></pre> MetricLogger can accept <code>str</code> or <code>List[str]</code> as <code>aggregate_fn</code>,  in this format it supports the following metrics:</p> Name Function \"median\" <code>np.median</code> \"min\" <code>np.min</code> \"max\" <code>np.max</code> \"std\" <code>np.std</code>"},{"location":"callbacks/metric_logger/#preprocessing","title":"Preprocessing","text":"<p>Sometimes metrics require some preprocessing. In this case, keys of <code>single_metrics</code> dict must be callable objects. <pre><code>from sklearn.metrics import accuracy_score, recall_score\nthreshold = lambda y, x: (y &gt; 0.5, x)\nsingle_metrics = {threshold: [accuracy_score, recall_score()]} \n# or\nsingle_metrics = {threshold: {\"acc\": accuracy_score, \"rec\": recall_score}}\n# or\nsingle_metrics = {threshold: recall_score}\n...\n</code></pre></p>"},{"location":"callbacks/metric_logger/#individual-metrics","title":"Individual Metrics","text":"<p>While computing <code>single_metrics</code>, one may appear in need of knowledge of metrics on each case. For this particular problem, the callback provides its users with <code>log_individual_metrics</code> flag. Being set to <code>True</code> it forces the callback to store table of metrics in the following format:</p> Name metric1 metric2 batch_idx0_0 some_value some_value batch_idx0_1 some_value some_value ... ... ... batch_idxn_m some_value some_value <p>For each set (e.g. <code>val</code>, <code>test</code>) and each <code>dataloader_idx</code>, MetricLogger stores separate table. By default aforementioned tables are saved to <code>default_root_dir</code> of lightning's Trainer, in the format of <code>set_name/dataloader_idx.csv</code> (e.g. <code>val/dataloader_0.csv</code>). If loggers you use have method <code>log_table</code> (e.g. <code>WandbLogger</code>),  then this method will receive key and each table in the format of <code>pd.DataFrame</code>. Code from <code>metric_logger.py</code>: <pre><code>logger.log_table(f\"{key}/dataloader_{dataloader_idx}\", dataframe=dataframe)\n</code></pre> where key is the current state of trainer (<code>val</code> or <code>test</code>).  </p> <p>Since lightning allows to use <code>batch_idx</code>, these indexes are used for metrics dataframes. But there can be more than one object in batch. To overcome this issue we iterate over batch and mark each object with the next index:  <pre><code>for i, object in enumerate(batch):\nobject_idx = f\"{batch_idx}_{i}\"\n</code></pre> If all batches consist of single object, then <code>\"_{i}\"</code> is removed.</p>"},{"location":"callbacks/metric_logger/#reference","title":"Reference","text":""},{"location":"callbacks/metric_logger/#thunder.callbacks.metric_logger.MetricLogger","title":"thunder.callbacks.metric_logger.MetricLogger","text":"<pre><code>thunder.callbacks.metric_logger.MetricLogger(single_metrics: Dict = None, group_metrics: Dict = None, aggregate_fn: Union[Dict[str, Callable], str, Callable, List[Union[str, Callable]]] = None, log_individual_metrics: bool = False)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>single_metrics</code> <code>Dict</code> <p>Metrics that are calculated on each object separately and then aggregated.</p> <code>None</code> <code>group_metrics</code> <code>Dict</code> <p>Metrics that are calculated on entire dataset.</p> <code>None</code> <code>aggregate_fn</code> <code>Union[Dict[str, Callable], str, Callable, List[Union[str, Callable]]]</code> <p>How to aggregate metrics. By default it computes mean value. If yoy specify something, then the callback will compute mean and the specified values.</p> <code>None</code> <code>log_individual_metrics</code> <code>bool</code> <p>If True, logs table for case-wise metrics (if logger has <code>log_table</code> method) and saves table to csv file.</p> <code>False</code>"},{"location":"callbacks/time_profiler/","title":"TimeProfiler","text":"<p>Lightning Callback which allows you to measure the time each step takes and log it during the training process.</p>"},{"location":"callbacks/time_profiler/#logged-values","title":"Logged values","text":"<p>TimeProfiler logs the following steps:</p> Name Logged by default Description train batch Time taken by forward, optimizer step, and backward during train step. validation batch Time taken by forward during validation step. train epoch Time taken by train epoch without validation. validation epoch Time taken by validation epoch. avg train downtime* Average downtime in training step. avg val downtime Average downtime in validation step. backward Time taken by backprop. optimizer step Time taken by optimizer. total train downtime Total downtime in training epoch. total val downtime Total downtime in validation epoch. <p>*Downtime - the process during which model does not work (e.g. data loader is working now)  </p>"},{"location":"callbacks/time_profiler/#usage","title":"Usage","text":"<pre><code>from thunder.callbacks import TimeProfiler\nfrom lightning import Trainer\n# logs default keys and in addition backward and optimizer step\ntrainer = Trainer(callbacks=[TimeProfiler(\"backward\", \"optimizer step\")])\n</code></pre>"},{"location":"callbacks/time_profiler/#reference","title":"Reference","text":""},{"location":"callbacks/time_profiler/#thunder.callbacks.time_profiler.TimeProfiler","title":"thunder.callbacks.time_profiler.TimeProfiler","text":"<pre><code>thunder.callbacks.time_profiler.TimeProfiler(*keys: Union[str, bool])\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>Union[str, bool]</code> <p>Optional keys for logging. If set to <code>True</code> it will log all keys.</p> <code>()</code>"},{"location":"cli/","title":"Command Line Interface","text":""},{"location":"cli/#requirements-lazycon","title":"Requirements: lazycon","text":"<p>Thunder provides its users with CLI to bring convenience and comfort into experiment building and execution routine.</p> <p>For any help you can use <pre><code>thunder --help\n</code></pre></p>"},{"location":"cli/#building-an-experiment","title":"Building an experiment","text":"<p>In order to build an experiment, you can execute the follwing command: <pre><code>thunder build /path/to/config /path/to/experiment\n</code></pre> It will create a folder with built configs in it.  </p>"},{"location":"cli/#overriding-config-entries","title":"Overriding config entries","text":"<p>While conducting experiments one can find themselves in constant need of changing significant number of parameters. But it is not convenient to always do it via IDE or any other code editor.  Thunder gives an ability to override the values while building an experiment.</p> <p>If in your config you have <pre><code>batch_size = 1\nlr = 0.01\n</code></pre> You can override it using <code>-u</code> flag: <pre><code>thunder build /path/to/config /path/to/experiment -u batch_size=2 -u lr=0.001 </code></pre> <code>batch_size</code> and <code>lr</code> will be assigned 2 and 0.001 respectively.</p>"},{"location":"cli/#running-an-experiment","title":"Running an experiment","text":"<p>You can run built experiment by executing the next command: <pre><code>thunder run /path/to/experiment\n</code></pre> Under the hood thunder extracts necessary entries (e.g. model and trainer) from your built config and executes <code>trainer.run(model, train_data, ...)</code>.</p>"},{"location":"cli/#backend","title":"Backend","text":"<p>As default options Thunder supports several backends: - cli (default) - slurm</p> <p>You can switch between them by specifying <code>--backend</code> flag.  <pre><code>thunder run /path/to/experiment/ --backend slurm -c 4 -r 100G </code></pre> The command shown above will run SLURM job with 4 CPUs and 100G of RAM.</p>"},{"location":"cli/#predefined-run-configs","title":"Predefined run configs","text":"<p>You can predefine run configs to avoid reentering the same flags. Create <code>.config/thunder/backends.yml</code> in you home directory.  Now you can specify config name and its parameters: <pre><code>run_config_name:\nbackend: slurm\nconfig:\nram: 100G\ncpu: 4\ngpu: 1\npartition: partition_name\n</code></pre> In order to run an experiment with predefined parameters,  use <code>--backend</code> flag as in previous section: <pre><code>thunder run /path/to/experiment/ --backend run_config_name\n</code></pre> You can overwrite parameters if you want to (e.g. 8 CPUs instead of 4): <pre><code>thunder run /path/to/experiment/ --backend run_config_name -c 8\n</code></pre></p>"},{"location":"cli/#placeholders","title":"Placeholders","text":"<p>Some loggers and other tools in your experiment may require name  of the experiment. We find it convenient to use name of the folder you  build your experiment into as the name of the experiment for loggers.  Example with <code>WandbLogger</code>: <pre><code>from lightning.pytorch.loggers import WandbLogger\nfrom thunder.placeholders import ExpName, GroupName\nlogger = WandbLogger(name=ExpName, group=GroupName)\n</code></pre> In this case <code>GroupName</code> - name of the folder with built experiment and <code>ExpName</code> - name of the split.</p>"},{"location":"cli/#wandb-sweeps-integration","title":"WandB Sweeps integration","text":"<p>WandB has hyperparameters tuning system called Sweeps. Sweeps allow you to run multiple experiment with predefined grid of parameters and compare run results. However, we find default sweep execution system very inconvenient when it comes to running experiments on cluster.</p> <p>After running a few experiments with  WandB Logger,  you can create sweep configuration.  WandB will give a command <code>wandb agent project/sweep_id</code>. You can copy it and paste it into the following command: <pre><code>thunder PASTE_HERE /path/to/config /path/to/experiment </code></pre></p>"},{"location":"configs/","title":"Lazycon","text":"<p>Thunder embraces the power of lazycon allowing you to build configs for your  experiments. </p>"},{"location":"configs/#config-structure","title":"Config structure","text":"<p>Correct config should contain the following objects:</p> Name Required Description <code>trainer</code> Lightning Trainer instance. <code>module</code> LightningModule instance. <code>train_data</code> Loader of training data. <code>val_data</code> Loader of validation data. <code>test_data</code> Loader of test data. <code>datamodule</code> LightningDataModule instance, replaces <code>train_data</code>, <code>val_data</code> and <code>test_data</code> if specified."},{"location":"configs/#executing-a-config","title":"Executing a config","text":"<p>Thunder has its own Command Line Interface,  about which you can read here.</p>"},{"location":"core/thunder_module/","title":"ThunderModule","text":"<p>ThunderModule inherits everything from LightningModule and implements essential methods for most common training pipelines.</p>"},{"location":"core/thunder_module/#from-lightning-to-thunder","title":"From Lightning to Thunder","text":"<p>Most common pipelines are implemented in lightning in the following way: <pre><code>from lightning import LightningModule\nclass Model(LightningModule):\ndef __init__(self):\nself.architecture: nn.Module = ...\nself.metrics = ... # smth like Dict[str, Callable]\ndef forward(self, *args, **kwargs):\nreturn self.architecture(*args, **kwargs)\ndef criterion(self, x, y):\n...\ndef training_step(self, batch, batch_idx):\nx, y = batch\nreturn self.criterion(self(x), y)\ndef validation_step(self, batch, batch_idx, dataloader_idx):\n# forward and metrics computation or output preservation\n...\ndef test_step(self, batch, batch_idx, dataloader_idx):\n# forward and metrics computation or output preservation\n...\ndef configure_optimizers(self):\nreturn Adam(...), StepLR(...)\n</code></pre></p> <p>ThunderModule offers an implementation of necessary steps shown above. <pre><code>from thunder import ThunderModule\narchitecture: nn.Module = ...\ncriterion = CrossEntropy()\noptimizer = Adam(architecture.parameters())\nscheduler = StepLR(optimizer)\nmodel = ThunderModule(architecture, criterion,\noptimizer=optimizer, lr_scheduler=scheduler)\n</code></pre></p>"},{"location":"core/thunder_module/#configuring-optimizers","title":"Configuring Optimizers","text":"<p>For extra information see this. Lightning requires optimizers and learning rate policies to be defined inside <code>configure_optimizers</code> method. Using ThunderModule allows you to pass the following configurations of  optimizers and learning rate schedulers:</p> <pre><code>from torch import nn\nfrom torch.optim.lr_scheduler import LRScheduler\nfrom torch.optim import Adam\narchitecture = nn.Linear(2, 2)\n</code></pre>"},{"location":"core/thunder_module/#no-scheduling","title":"No scheduling","text":"<pre><code>optimizer = Adam(architecture.parameters())\nmodel = ThunderModule(..., optimizer=optimizer)\n</code></pre>"},{"location":"core/thunder_module/#defining-optimizer-and-scheduler","title":"Defining optimizer and scheduler","text":"<pre><code>optimizer = Adam(architecture.parameters())\nlr_scheduler = LRScheduler(optimizer)\nmodel = ThunderModule(..., optimizer=optimizer, lr_scheduler=lr_scheduler)\n</code></pre>"},{"location":"core/thunder_module/#defining-no-optimizer","title":"Defining no optimizer","text":"<pre><code>lr_scheduler = LRScheduler(optimizer)\nmodel = ThunderModule(..., lr_scheduler=lr_scheduler)\n</code></pre>"},{"location":"core/thunder_module/#multiple-optimizers","title":"Multiple Optimizers","text":"<p>Thunder just as lightning supports configuration with more than 1 optimizer. If such configuration is to be used, manual optimization is required. Guide on manual optimization</p> <p>In thunder you can pass lists of optimizers and schedulers to ThunderModule. <pre><code>class ThunderModuleManual(ThunderModule):\ndef __init__(self, *args, **kwargs):\nsuper().__init__(*args, **kwargs)\nself.automatic_optimization = False\noptimizers = [Adam(module1.parameters()), Adam(module2.parameters())]\nlr_schedulers = [Scheduler(opt) for opt in optimizers]\nmodel = ThunderModuleManual(..., optimizer=optimizers, lr_scheduler=lr_schedulers)\n</code></pre></p>"},{"location":"core/thunder_module/#thunder-policies","title":"Thunder Policies","text":"<p>As shown above, torch schedulers require optimizer(s) to be passed to them before they are given to ThunderModule. It is not very convenient, and also they lack some basic  functionality. You can use thunder policies just like torch schedulers: <pre><code>from thunder.policy import Switch\noptimizers = [Adam(module1.parameters()), Adam(module2.parameters())]\nlr_schedulers = [Switch({1: 0.001}), Switch({2: 0.001})]\nmodel = ThunderModuleManual(..., optimizer=optimizers, lr_scheduler=lr_schedulers)\n</code></pre></p> <p>For extra information see Thunder Policies Docs.</p>"},{"location":"core/thunder_module/#inference","title":"Inference","text":"<p>During inference step, ThunderModule uses Predictors in order to preprocess data and make inverse transforms after passing data through the model. Default predictor is just an identity function.</p> <p>For more on predictors see Thunder Predictors Docs.</p>"},{"location":"core/thunder_module/#batch-transfer","title":"Batch Transfer","text":"<p>ThunderModule transfers training batches to device by default. However, during  inference batch remains on the device, on which it was received from data loader.  Transferring happens later in the <code>inference_step</code>, which is invoked in <code>validation_step</code>, <code>test_step</code> and <code>predict_step</code>.</p>"},{"location":"core/thunder_module/#reference","title":"Reference","text":""},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule","title":"thunder.torch.core.ThunderModule","text":"<pre><code>thunder.torch.core.ThunderModule(architecture: nn.Module, criterion: Callable, n_targets: int = 1, activation: Callable = identity, optimizer: Union[List[Optimizer], Optimizer] = None, lr_scheduler: Union[List[LRScheduler], LRScheduler] = None, predictor: BasePredictor = None, n_val_targets: int = None)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>architecture</code> <code>nn.Module</code> <p>Model architecture used to conduct forward pass.</p> required <code>criterion</code> <code>Callable</code> <p>Criterion to optimize.</p> required <code>n_targets</code> <code>int</code> <p>Number of target values in train and inference batches, if negative, then ...</p> <code>1</code> <code>activation</code> <code>Callable</code> <p>Final activation function for inference, identity by default.</p> <code>identity</code> <code>optimizer</code> <code>Union[List[Optimizer], Optimizer]</code> <p>Optimizers.</p> <code>None</code> <code>lr_scheduler</code> <code>Union[List[LRScheduler], LRScheduler]</code> <p>Learning Rate policies.</p> <code>None</code> <code>predictor</code> <code>BasePredictor</code> <p>Predictor for inference.</p> <code>None</code> <code>n_val_targets</code> <code>int</code> <p>Number of target values for inference, if set to None assumes value of <code>n_targets</code>.</p> <code>None</code> Source code in <code>thunder/torch/core.py</code> <pre><code>def __init__(\nself,\narchitecture: nn.Module,\ncriterion: Callable,\nn_targets: int = 1,\nactivation: Callable = identity,\noptimizer: Union[List[Optimizer], Optimizer] = None,\nlr_scheduler: Union[List[LRScheduler], LRScheduler] = None,\npredictor: BasePredictor = None,\nn_val_targets: int = None\n):\n\"\"\"\n    Parameters\n    ----------\n    architecture: nn.Module\n        Model architecture used to conduct forward pass.\n    criterion: Callable\n        Criterion to optimize.\n    n_targets: int\n        Number of target values in train and inference batches, if negative, then ...\n    activation: Callable\n        Final activation function for inference, identity by default.\n    optimizer: Union[List[Optimizer], Optimizer]\n        Optimizers.\n    lr_scheduler: Union[List[LRScheduler], LRScheduler]\n        Learning Rate policies.\n    predictor: BasePredictor.\n        Predictor for inference.\n    n_val_targets: int\n        Number of target values for inference, if set to None assumes value of `n_targets`.\n    \"\"\"\nsuper().__init__()\nself.architecture = architecture\nself.criterion = criterion\nself.n_targets = n_targets\nself.n_val_targets = n_targets if n_val_targets is None else n_val_targets\nself.activation = activation\nself.optimizer = optimizer\nself.lr_scheduler = lr_scheduler\nself.predictor = predictor if predictor else Predictor()\n</code></pre>"},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule.training_step","title":"training_step","text":"<pre><code>training_step(batch: Tuple[Tensor, ...], batch_idx: int) -&gt; STEP_OUTPUT\n</code></pre> Source code in <code>thunder/torch/core.py</code> <pre><code>def training_step(self, batch: Tuple[Tensor, ...], batch_idx: int) -&gt; STEP_OUTPUT:\nx, y = batch[: -self.n_targets], batch[-self.n_targets:]\nreturn self.criterion(self(*x), *y)\n</code></pre>"},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule.validation_step","title":"validation_step","text":"<pre><code>validation_step(batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; STEP_OUTPUT\n</code></pre> Source code in <code>thunder/torch/core.py</code> <pre><code>def validation_step(self, batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; STEP_OUTPUT:\nreturn self.inference_step(batch, batch_idx, dataloader_idx)\n</code></pre>"},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule.test_step","title":"test_step","text":"<pre><code>test_step(batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; STEP_OUTPUT\n</code></pre> Source code in <code>thunder/torch/core.py</code> <pre><code>def test_step(self, batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; STEP_OUTPUT:\nreturn self.inference_step(batch, batch_idx, dataloader_idx)\n</code></pre>"},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule.predict_step","title":"predict_step","text":"<pre><code>predict_step(batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; Any\n</code></pre> Source code in <code>thunder/torch/core.py</code> <pre><code>def predict_step(self, batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; Any:\nreturn self.inference_step(batch, batch_idx, dataloader_idx)\n</code></pre>"},{"location":"core/thunder_module/#thunder.torch.core.ThunderModule.inference_step","title":"inference_step","text":"<pre><code>inference_step(batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; Any\n</code></pre> Source code in <code>thunder/torch/core.py</code> <pre><code>def inference_step(self, batch: Tuple, batch_idx: int, dataloader_idx: int = 0) -&gt; Any:\nx, y = map(squeeze_first, (batch[:-self.n_val_targets], batch[-self.n_val_targets:]))\nreturn self.predictor([x], self.predict)[0], y\n</code></pre>"},{"location":"examples/","title":"Examples","text":"<p>Here are some examples of Thunder experiments.</p> Name Description Totalsegmentator LowRes Low resolution segmentation of liver in Totalsegmentator MNIST Classifier MNIST classifier config"},{"location":"examples/mnist/","title":"Mnist","text":"<pre><code>import numpy as np\nimport torch\nfrom lightning import Trainer\nfrom lightning.pytorch.callbacks import ModelCheckpoint\nfrom lightning.pytorch.loggers import WandbLogger\nfrom sklearn.metrics import accuracy_score\nfrom thunder import ThunderModule\nfrom thunder.callbacks import MetricLogger\nfrom thunder.placeholders import ExpName, GroupName\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torchvision.datasets import MNIST\nBATCH_SIZE = 256\ntrain_ds = MNIST(\".\", train=True, download=True, transform=transforms.ToTensor())\nval_ds = MNIST(\".\", train=False, download=True, transform=transforms.ToTensor())\ntrain_data = DataLoader(train_ds, batch_size=BATCH_SIZE)\nval_data = DataLoader(val_ds, batch_size=BATCH_SIZE)\narchitecture = nn.Sequential(nn.Flatten(), torch.nn.Linear(28 * 28, 10))\nmodule = ThunderModule(\narchitecture, nn.CrossEntropyLoss(), optimizer=torch.optim.Adam(architecture.parameters())\n)\n# Initialize a trainer\ntrainer = Trainer(\ncallbacks=[ModelCheckpoint(save_last=True), MetricLogger(group_metrics={lambda y, x: (np.argmax(y), x): accuracy_score})],\naccelerator=\"auto\",\ndevices=1,\nmax_epochs=100,\nlogger=WandbLogger(\nname=ExpName,\ngroup=GroupName,\nproject=\"thunder-examples\",\nentity=\"arseniybelkov\",\n),\n)\n</code></pre>"},{"location":"examples/mnist/#source","title":"Source","text":"<p>Full source code is available at thunder-examples</p>"},{"location":"examples/totalsegm_lowres/","title":"Low Resolution Liver Segmentation","text":""},{"location":"examples/totalsegm_lowres/#requirements-deep-pipe-amid-connectome","title":"Requirements: deep-pipe, amid, connectome","text":"<p>Deep-Pipe was primarly used for metrics and batch combinations.</p>"},{"location":"examples/totalsegm_lowres/#main-config","title":"Main config","text":"<pre><code>from functools import partial\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom amid.totalsegmentator import Totalsegmentator\nfrom connectome import Apply, CacheToDisk, CacheToRam, Chain, Filter\nfrom dpipe import layers\nfrom dpipe.batch_iter import combine_pad\nfrom dpipe.im.metrics import dice_score, precision, recall\nfrom dpipe.torch.functional import weighted_cross_entropy_with_logits\nfrom lightning import Trainer\nfrom lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint\nfrom lightning.pytorch.loggers import WandbLogger\nfrom sklearn.model_selection import train_test_split\nfrom thunder import ThunderModule\nfrom thunder.callbacks import MetricLogger, TimeProfiler\nfrom thunder.layout import SingleSplit\nfrom thunder.placeholders import ExpName, GroupName\nfrom thunder.policy import Switch\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader\nfrom thunder_examples.dataset import (ConToTorch, NormalizeCT, RotateTotalsegm,\nZoom)\nSEED = 0xBadCafe\ntotalsegmentator = Totalsegmentator(\"/shared/data/Totalsegmentator_dataset.zip\")\\\n                    &gt;&gt; Filter(lambda study_type, split: study_type == \"ct abdomen-pelvis\" and split == \"train\")\npreprocessing = Chain(RotateTotalsegm(), Zoom(n=0.3), NormalizeCT(max_=200, min_=-200))\ndataset = Chain(totalsegmentator,\npreprocessing,\nCacheToRam())\nlayout = SingleSplit(dataset, train=0.7, val=0.3)\nbatch_size = 2\nbatches_per_epoch = 256\nmax_epochs = 200\ntrain_data = DataLoader(\nConToTorch(layout.train &gt;&gt; Apply(image=lambda x: x[None], liver=lambda x: x[None]), ['image', 'liver']),\nbatch_size=batch_size, num_workers=4,\nshuffle=True, collate_fn=partial(combine_pad, padding_values=np.min))\nval_data = DataLoader(\nConToTorch(layout.val &gt;&gt; Apply(image=lambda x: x[None], liver=lambda x: x[None]), ['image', 'liver']),\nbatch_size=batch_size, collate_fn=partial(combine_pad, padding_values=np.min), num_workers=4)\narchitecture = nn.Sequential(\nnn.Conv3d(1, 8, kernel_size=3, padding=1),\nlayers.FPN(\nlayers.ResBlock3d, nn.MaxPool3d(2), nn.Identity(),\nlayers.fpn.interpolate_merge(lambda x, y: torch.cat([x, y], 1), order=1),\n[\n[[8, 16, 16], [32, 16, 8]],\n[[16, 32, 32], [64, 32, 16]],\n[[32, 64, 64], [128, 64, 32]],\n[[64, 128, 128], [256, 128, 64]],\n[128, 256, 128],\n],\nkernel_size=3, padding=1,\n),\nlayers.PreActivation3d(8, 1, kernel_size=3, padding=1),\n)\ncriterion = weighted_cross_entropy_with_logits\nmodule = ThunderModule(architecture, criterion, activation=nn.Sigmoid(),\noptimizer=Adam(architecture.parameters()),\nlr_scheduler=Switch({0: 1e-3, 50: 1e-4, 150: 1e-5}))\ntrainer = Trainer(\ncallbacks=[\nMetricLogger({lambda y, x: (y &gt; 0.5, x &gt; 0.5): [precision, recall, dice_score]}, aggregate_fn=[\"std\", \"max\", \"min\"]),\nTimeProfiler(),\nLearningRateMonitor(\"epoch\"),\nModelCheckpoint(save_last=True),\n],\nlimit_train_batches=batches_per_epoch,\naccelerator='cuda', precision=16,\nmax_epochs=max_epochs,\nlogger=WandbLogger(name=ExpName, group=GroupName, project='thunder-examples', entity='arseniybelkov'))\n</code></pre>"},{"location":"examples/totalsegm_lowres/#contotorch","title":"ConToTorch","text":"<p>ConTotch is a wrapper for connectome dataset for it can be passed to torch DataLoader. <pre><code>from torch.utils.data import Dataset\nclass ConToTorch(Dataset):\ndef __init__(self, dataset, fields):\nself.loader = dataset._compile(fields)\nself.ids = dataset.ids\ndef __len__(self):\nreturn len(self.ids)\ndef __getitem__(self, item):\nreturn self.loader(self.ids[item])\n</code></pre></p>"},{"location":"examples/totalsegm_lowres/#source","title":"Source","text":"<p>Full source code is available at thunder-examples</p>"},{"location":"inference/","title":"Inference","text":"<p>For matters of inference, thunder offers Predictors - objects that  can transform data before and after model's inference.</p> <p>In ThunderModule Predictor is used as default inference runner.</p>"},{"location":"inference/#predictors","title":"Predictors","text":""},{"location":"inference/#thunder.predict.predict","title":"thunder.predict.predict","text":""},{"location":"inference/#thunder.predict.predict.BasePredictor","title":"BasePredictor","text":"<p>Base class for all predictors.</p>"},{"location":"inference/#thunder.predict.predict.BasePredictor.forward","title":"forward  <code>abstractmethod</code>","text":"<pre><code>forward(batches: Iterable) -&gt; Iterable\n</code></pre> <p>Process stream of batches before model inference.</p> Source code in <code>thunder/predict/predict.py</code> <pre><code>@abstractmethod\ndef forward(self, batches: Iterable) -&gt; Iterable:\n\"\"\"Process stream of batches before model inference.\"\"\"\nraise NotImplementedError(\"You must implement forward method\")\n</code></pre>"},{"location":"inference/#thunder.predict.predict.BasePredictor.backward","title":"backward  <code>abstractmethod</code>","text":"<pre><code>backward(predicts: Iterable) -&gt; Iterable\n</code></pre> <p>Post-process stream of predictions.</p> Source code in <code>thunder/predict/predict.py</code> <pre><code>@abstractmethod\ndef backward(self, predicts: Iterable) -&gt; Iterable:\n\"\"\"Post-process stream of predictions.\"\"\"\nraise NotImplementedError(\"You must implement backward method\")\n</code></pre>"},{"location":"inference/#thunder.predict.predict.BasePredictor.__call__","title":"__call__","text":"<pre><code>__call__(batches: Iterable, predict_fn: Callable) -&gt; Iterable\n</code></pre> Source code in <code>thunder/predict/predict.py</code> <pre><code>def __call__(self, batches: Iterable, predict_fn: Callable) -&gt; Iterable:\nreturn self.run(batches, predict_fn)\n</code></pre>"},{"location":"inference/#thunder.predict.predict.BasePredictor.run","title":"run","text":"<pre><code>run(batches: Iterable, predict_fn: Callable) -&gt; Iterable\n</code></pre> <p>Runs preprocessing, inference and postprocessing.</p> Source code in <code>thunder/predict/predict.py</code> <pre><code>def run(self, batches: Iterable, predict_fn: Callable) -&gt; Iterable:\n\"\"\"Runs preprocessing, inference and postprocessing.\"\"\"\nreturn self.backward(map(predict_fn, self.forward(batches)))\n</code></pre>"},{"location":"inference/#thunder.predict.predict.InfinitePredictor","title":"InfinitePredictor","text":"<p>Useful for running inference on infinite stream of data.</p>"},{"location":"inference/#thunder.predict.predict.InfinitePredictor.forward","title":"forward","text":"<pre><code>forward(batches: Iterable) -&gt; Iterable\n</code></pre> Source code in <code>thunder/predict/predict.py</code> <pre><code>def forward(self, batches: Iterable) -&gt; Iterable:\nyield from batches\n</code></pre>"},{"location":"inference/#thunder.predict.predict.InfinitePredictor.backward","title":"backward","text":"<pre><code>backward(predicts: Iterable) -&gt; Iterable\n</code></pre> Source code in <code>thunder/predict/predict.py</code> <pre><code>def backward(self, predicts: Iterable) -&gt; Iterable:\nyield from predicts\n</code></pre>"},{"location":"inference/#thunder.predict.predict.Predictor","title":"Predictor","text":"<p>Assumes using finite amount of data for inference to be run on.</p>"},{"location":"inference/#thunder.predict.predict.Predictor.run","title":"run","text":"<pre><code>run(batches: Iterable, predict_fn: Callable) -&gt; Iterable\n</code></pre> Source code in <code>thunder/predict/predict.py</code> <pre><code>def run(self, batches: Iterable, predict_fn: Callable) -&gt; Iterable:\nreturn tuple(super().run(batches, predict_fn))\n</code></pre>"},{"location":"inference/#thunder.predict.predict.Decorated","title":"Decorated","text":"<pre><code>Decorated(*decorators: Callable)\n</code></pre> <p>Decorates inference function Example</p> <p>Decorated(f, g, h)</p>"},{"location":"inference/#thunder.predict.predict.Decorated--inside-decorated","title":"inside Decorated","text":"<p>predict_fn = f(g(h(predict_fn)))</p> Source code in <code>thunder/predict/predict.py</code> <pre><code>def __init__(self, *decorators: Callable):\nself.decorators = compose(*decorators)\n</code></pre>"},{"location":"inference/#thunder.predict.predict.Decorated.decorators","title":"decorators  <code>instance-attribute</code>","text":"<pre><code>decorators = compose(*decorators)\n</code></pre>"},{"location":"inference/#thunder.predict.predict.Decorated.run","title":"run","text":"<pre><code>run(batches: Iterable, predict_fn: Callable) -&gt; Iterable\n</code></pre> Source code in <code>thunder/predict/predict.py</code> <pre><code>def run(self, batches: Iterable, predict_fn: Callable) -&gt; Iterable:\nreturn super().run(batches, self.decorators(predict_fn))\n</code></pre>"},{"location":"layout/","title":"Layout","text":"<p>Layout instances are responsible for splitting your datasets and managing which data fold is used for each experiment. They also check reproducibility of your data splits.</p>"},{"location":"layout/#thunder-layouts","title":"Thunder Layouts","text":"Name Description Split Layout for K fold cross-validation SingleSplit Layout with several sets (e.g. train + val + test) <p>All Layout subclasses follow common interface </p>"},{"location":"layout/#thunder.layout.interface.Layout","title":"thunder.layout.interface.Layout","text":""},{"location":"layout/#thunder.layout.interface.Layout.build","title":"build  <code>abstractmethod</code>","text":"<pre><code>build(experiment: Path, config: Config) -&gt; Iterable[Node]\n</code></pre> Source code in <code>thunder/layout/interface.py</code> <pre><code>@abstractmethod\ndef build(self, experiment: Path, config: Config) -&gt; Iterable[Node]:\npass\n</code></pre>"},{"location":"layout/#thunder.layout.interface.Layout.load","title":"load  <code>abstractmethod</code>","text":"<pre><code>load(experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]\n</code></pre> Source code in <code>thunder/layout/interface.py</code> <pre><code>@abstractmethod\ndef load(self, experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]:\npass\n</code></pre>"},{"location":"layout/#thunder.layout.interface.Layout.set","title":"set  <code>abstractmethod</code>","text":"<pre><code>set(**kwargs)\n</code></pre> Source code in <code>thunder/layout/interface.py</code> <pre><code>@abstractmethod\ndef set(self, **kwargs):\npass\n</code></pre>"},{"location":"layout/splits/","title":"Splits","text":""},{"location":"layout/splits/#thunder.layout.split.Split","title":"thunder.layout.split.Split","text":"<pre><code>thunder.layout.split.Split(split: SplitType, entries: Sequence, *args: Any, names: Optional[Sequence[str]] = None, **kwargs: Any)\n</code></pre> <p>Splits data according to split function.</p> <p>Parameters:</p> Name Type Description Default <code>split</code> <code>SplitType</code> <p>Split function, or a sklearn splitter.</p> required <code>entries</code> <code>Sequence</code> <p>Series of ids or torch Dataset or Connectome Layer.</p> required <code>args</code> <code>Any</code> <p>args for split.</p> <code>()</code> <code>names</code> <code>Optional[Sequence[str]]</code> <p>Names of folds, e.g. 'train', 'val', test'</p> <code>None</code> <code>kwargs</code> <code>Any</code> <code>{}</code> <code>kwargs</code> <code>Any</code> <code>{}</code> Source code in <code>thunder/layout/split.py</code> <pre><code>def __init__(self, split: SplitType, entries: Sequence, *args: Any, names: Optional[Sequence[str]] = None,\n**kwargs: Any):\n\"\"\"\n    Splits data according to split function.\n    Parameters\n    ----------\n    split: Callable\n        Split function, or a sklearn splitter.\n    entries: Sequence\n        Series of ids or torch Dataset or Connectome Layer.\n    args: Any\n        args for split.\n    names: Optional[Sequence[str]]\n        Names of folds, e.g. 'train', 'val', test'\n    kwargs: Any\n    kwargs for split.\n    \"\"\"\nif not callable(split):\nif not hasattr(split, 'split'):\nraise TypeError(f'Expected either a function, or a sklearn splitter, got {type(split)!r}')\nsplit = split.split\nids = entries_to_ids(entries)\n# TODO: safer way to unify types\nsplits = [tuple(map(jsonify, xs)) for xs in split(ids, *args, **kwargs)]\nif names is not None:\n# TODO\nassert len(set(names)) == len(names)\nassert len(splits[0]) == len(names)\nself.entries = entries\nself.splits = splits\nself.names = names\nself.fold: Optional[int] = None\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.Split.build","title":"build","text":"<pre><code>build(experiment: Path, config: Config)\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def build(self, experiment: Path, config: Config):\nconfig.dump(experiment / 'experiment.config')\nname = experiment.name\nfor fold, split in enumerate(self.splits):\nfolder = experiment / f'fold_{fold}'\nfolder.mkdir()\nsave(split, folder / 'split.json')\nlocal = config.copy().update(ExpName=f'{name}({fold})', GroupName=name)\nlocal.dump(folder / 'experiment.config')\nyield Node(name=str(fold))\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.Split.load","title":"load","text":"<pre><code>load(experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def load(self, experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]:\nfolder = experiment / f'fold_{node.name}'\nreturn Config.load(folder / 'experiment.config'), folder, {\n'fold': int(node.name),\n'split': tuple(load(folder / 'split.json')),\n}\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.Split.set","title":"set","text":"<pre><code>set(fold: int, split: Optional[Sequence[Sequence]] = None)\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def set(self, fold: int, split: Optional[Sequence[Sequence]] = None):\nself.fold = fold\nif split is None:\nwarnings.warn('No reference split provided. Your results might be inconsistent!', UserWarning)\nelse:\nif split != self.splits[fold]:\n# TODO: consistency error?\nraise ValueError\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.SingleSplit","title":"thunder.layout.split.SingleSplit","text":"<pre><code>thunder.layout.split.SingleSplit(entries: Sequence, *, shuffle: bool = True, random_state: Union[np.random.RandomState, int, None] = 0, **sizes: Union[int, float])\n</code></pre> <p>Creates single fold experiment, with custom number of sets.</p> <p>Parameters:</p> Name Type Description Default <code>entries</code> <code>Sequence</code> <p>Sequence of ids or</p> required <code>shuffle</code> <code>bool</code> <p>Whether to shuffle entries.</p> <code>True</code> <code>random_state</code> <code>Union[np.random.RandomState, int, None]</code> <code>0</code> <code>sizes</code> <code>Union[int, float]</code> <code>{}</code> Source code in <code>thunder/layout/split.py</code> <pre><code>def __init__(self, entries: Sequence, *, shuffle: bool = True,\nrandom_state: Union[np.random.RandomState, int, None] = 0,\n**sizes: Union[int, float]):\n\"\"\"\n    Creates single fold experiment, with custom number of sets.\n    Parameters\n    ----------\n    entries: Sequence\n        Sequence of ids or\n    shuffle: bool\n        Whether to shuffle entries.\n    random_state : Union[np.random.RandomState, int, None]\n    sizes: Union[int, float]\n    \"\"\"\nif not isinstance(random_state, np.random.RandomState):\nrandom_state = np.random.RandomState(random_state)\nids = entries_to_ids(entries)\nself.entries = entries\nself.split = dict(zip(sizes.keys(), multi_split(\nids, list(sizes.values()), shuffle=shuffle, random_state=random_state\n)))\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.SingleSplit.build","title":"build","text":"<pre><code>build(experiment: Path, config: Config)\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def build(self, experiment: Path, config: Config):\nconfig.dump(experiment / 'experiment.config')\nname = experiment.name\nsave(self.split, experiment / 'split.json')\nlocal = config.copy().update(ExpName=name, GroupName=name)\nlocal.dump(experiment / 'experiment.config')\nreturn []\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.SingleSplit.load","title":"load","text":"<pre><code>load(experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def load(self, experiment: Path, node: Optional[Node]) -&gt; Tuple[Config, Path, Dict[str, Any]]:\nreturn Config.load(experiment / 'experiment.config'), experiment, {\n'split': load(experiment / 'split.json'),\n}\n</code></pre>"},{"location":"layout/splits/#thunder.layout.split.SingleSplit.set","title":"set","text":"<pre><code>set(split: Optional[Dict[str, Sequence]] = None)\n</code></pre> Source code in <code>thunder/layout/split.py</code> <pre><code>def set(self, split: Optional[Dict[str, Sequence]] = None):\nif split is None:\nwarnings.warn('No reference split provided. Your results might be inconsistent!', UserWarning)\nelse:\nif split != self.split:\n# TODO: consistency error?\nraise ValueError\n</code></pre>"},{"location":"policy/","title":"Policy","text":"<p>Policies are objects that define how some value changes through time. Good example of them is Learning Rate Schedulers.  </p>"},{"location":"policy/#learning-rate-schedulers","title":"Learning Rate Schedulers","text":"<p>Contrary to default PyTorch Learning Rate schedulers, ours does not require an optimizer to be passed during initialization.</p>"},{"location":"policy/#thunder-schedulers","title":"Thunder Schedulers","text":"Name Description Multiply Multiplies lr on each step by specified factor. Schedule Assigns lr values according to specified callable. Switch Assigns lr values according to specified dict schedule. <p>See Learning Rate Schedulers docs </p>"},{"location":"policy/lr_schedulers/","title":"LR Schedulers","text":"<p>All schedulers in thunder are subclasses of <code>torch.optim.lr_scheduler.LRScheduler</code>. However, during initialization they do not require optimizer to be passed.</p>"},{"location":"policy/lr_schedulers/#usage","title":"Usage","text":"<p>We will use Switch as an example. <pre><code>from thunder.policy import Switch\nswitch = Switch({10: 0.001, 20: 0.001 / 10})\n</code></pre> We have just created a policy, but to make it work, it still needs an optimizers. Let's see how it works after being assembled. <pre><code>optimizer = Adam(...)\nscheduler(optimizer) # bounds optimizer to scheduler\n# or \n# scheduler = scheduler(optimizer)\n# You can also retrieve optimizer:\nopt = scheduler.optimizer\n</code></pre> After assigning optimizer to scheduler, policy instance will work just like usual torch scheduler.</p>"},{"location":"policy/lr_schedulers/#initial-lr","title":"Initial LR","text":"<p>All schedulers have <code>lr_init</code> parameters, if specified, it will be used as lr value on 0th step.</p>"},{"location":"policy/lr_schedulers/#reference","title":"Reference","text":""},{"location":"policy/lr_schedulers/#thunder.policy.Multiply","title":"thunder.policy.Multiply","text":"<p>Multiplies learning rate value on the specified factor in <code>mapping</code>. Example:     <pre><code>    sch = Multiply({1: 0.1, 4: 0.3})\n</code></pre>     if initial learning rate is 1e-3, learning rate will be: 1e-3, 1e-4, 1e-4, 1e-4, 3-e5, ...</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <p>Maps epoch to factor, keeping the last value between the epochs.</p> required <code>lr_init</code> <p>Initial learning rate for each group of parameters.</p> required"},{"location":"policy/lr_schedulers/#thunder.policy.Multiply.mapping","title":"mapping  <code>instance-attribute</code>","text":"<pre><code>mapping: Union[List[Dict[int, float]], Dict[int, float]]\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Multiply.get_lr","title":"get_lr","text":"<pre><code>get_lr() -&gt; List[float]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def get_lr(self) -&gt; List[float]:\nreturn [\nparam_group[\"lr\"] * mapping.get(self.last_epoch, 1)\nfor param_group, mapping in zip_equal(self.optimizer.param_groups, self.current_mapping)\n]\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Multiply.state_dict","title":"state_dict","text":"<pre><code>state_dict() -&gt; Dict[str, Any]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def state_dict(self) -&gt; Dict[str, Any]:\nreturn super().state_dict()\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Multiply.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict)\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def load_state_dict(self, state_dict):\nsuper().load_state_dict(state_dict)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Schedule","title":"thunder.policy.Schedule","text":"<p>Assigns learning rate values received from callable mapping. Example:     <pre><code>sch = Schedule(np.cos)\n</code></pre>     lr will have values of np.cos(epoch_number)</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <p>Maps epoch to value.</p> required <code>lr_init</code> <p>Initial learning rate for each group of parameters.</p> required"},{"location":"policy/lr_schedulers/#thunder.policy.Schedule.mapping","title":"mapping  <code>instance-attribute</code>","text":"<pre><code>mapping: Union[List[Callable], Callable]\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Schedule.get_lr","title":"get_lr","text":"<pre><code>get_lr() -&gt; List[float]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def get_lr(self) -&gt; List[float]:\nreturn juxt(self.current_mapping)(self.last_epoch)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Schedule.state_dict","title":"state_dict","text":"<pre><code>state_dict() -&gt; Dict[str, Any]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def state_dict(self) -&gt; Dict[str, Any]:\nreturn super().state_dict(\"mapping\")\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Schedule.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict: Dict[str, Any]) -&gt; None\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\nsuper().load_state_dict(state_dict)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Switch","title":"thunder.policy.Switch","text":"<p>Assigns learning rate values received from dict mapping. Example:     <pre><code>sch = Switch({0: 1e-4, 2: 1e-10)\n</code></pre>     lr: 1e-4, 1e-4, 1e-10, 1e-10, ...</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <p>Maps specified epochs to specified values, preserving learning rate between epochs.</p> required <code>lr_init</code> <p>Initial learning rate for each group of parameters.</p> required"},{"location":"policy/lr_schedulers/#thunder.policy.Switch.mapping","title":"mapping  <code>instance-attribute</code>","text":"<pre><code>mapping: Union[List[Dict[int, float]], Dict[int, float]]\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Switch.get_lr","title":"get_lr","text":"<pre><code>get_lr() -&gt; List[float]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def get_lr(self) -&gt; List[float]:\nreturn [\nmapping.get(self.last_epoch, param_group[\"lr\"])\nfor param_group, mapping in zip_equal(self.optimizer.param_groups, self.current_mapping)\n]\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Switch.state_dict","title":"state_dict","text":"<pre><code>state_dict() -&gt; Dict[str, Any]\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def state_dict(self) -&gt; Dict[str, Any]:\nreturn super().state_dict()\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Switch.load_state_dict","title":"load_state_dict","text":"<pre><code>load_state_dict(state_dict: Dict[str, Any]) -&gt; None\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\nsuper().load_state_dict(state_dict)\n</code></pre>"},{"location":"policy/lr_schedulers/#base-classes","title":"Base classes","text":""},{"location":"policy/lr_schedulers/#thunder.policy","title":"thunder.policy","text":""},{"location":"policy/lr_schedulers/#thunder.policy.Policy","title":"Policy","text":"<pre><code>Policy()\n</code></pre> <p>Policy base class.</p> Source code in <code>thunder/policy.py</code> <pre><code>def __init__(self):\npass\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Policy.__call__","title":"__call__","text":"<pre><code>__call__(optimizer: Optimizer) -&gt; Policy\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def __call__(self, optimizer: Optimizer) -&gt; Policy:\nself.set_optimizer(optimizer)\nreturn self\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Policy.set_optimizer","title":"set_optimizer","text":"<pre><code>set_optimizer(optimizer: Optimizer) -&gt; None\n</code></pre> <p>Assigns optimizer to a scheduler</p> Source code in <code>thunder/policy.py</code> <pre><code>def set_optimizer(self, optimizer: Optimizer) -&gt; None:\n\"\"\"Assigns optimizer to a scheduler\"\"\"\nsuper().__init__(optimizer)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Policy.get_lr","title":"get_lr  <code>abstractmethod</code>","text":"<pre><code>get_lr() -&gt; List[float]\n</code></pre> <p>Computes new value of learning rate.</p> <p>Returns:</p> Type Description <code>List[float]</code> Source code in <code>thunder/policy.py</code> <pre><code>@abstractmethod\ndef get_lr(self) -&gt; List[float]:\n\"\"\"\n    Computes new value of learning rate.\n    Returns\n    -------\n    List[float]\n    \"\"\"\npass\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Policy.state_dict","title":"state_dict  <code>abstractmethod</code>","text":"<pre><code>state_dict(*keys: str) -&gt; Dict[str, Any]\n</code></pre> <p>Creates state dict of scheduler, excluding optimizer.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>str</code> <p>Names of attributes to be excluded from state_dict</p> <code>()</code> <p>Returns:</p> Type Description <code>Dict[str, Any]</code> Source code in <code>thunder/policy.py</code> <pre><code>@abstractmethod\ndef state_dict(self, *keys: str) -&gt; Dict[str, Any]:\n\"\"\"\n    Creates state dict of scheduler, excluding optimizer.\n    Parameters\n    ----------\n    keys: str\n        Names of attributes to be excluded from state_dict\n    Returns\n    -------\n    Dict[str, Any]\n    \"\"\"\nkeys = (*keys, \"optimizer\")\nreturn {key: value for key, value in self.__dict__.items() if key not in keys}\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.Policy.load_state_dict","title":"load_state_dict  <code>abstractmethod</code>","text":"<pre><code>load_state_dict(state_dict: Dict[str, Any]) -&gt; None\n</code></pre> <p>Loads state dict of scheduler</p> <p>Parameters:</p> Name Type Description Default <code>state_dict</code> <code>Dict[str, Any]</code> <p>State dict of scheduler.</p> required Source code in <code>thunder/policy.py</code> <pre><code>@abstractmethod\ndef load_state_dict(self, state_dict: Dict[str, Any]) -&gt; None:\n\"\"\"\n    Loads state dict of scheduler\n    Parameters\n    ----------\n    state_dict: Dict[str, Any]\n        State dict of scheduler.\n    \"\"\"\nself.__dict__.update(state_dict)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy","title":"MappingPolicy","text":"<pre><code>MappingPolicy(mapping, lr_init: Union[List[float], float] = 0.001)\n</code></pre> <p>Base class for policy with mapping. Mapping can be a dict or a function (it should also be a list of latter types in case of multiple param groups). Mapping is the binding between epoch or step number and learning rate value.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <p>Binding of epoch or step number and learning rate.</p> required <code>lr_init</code> <code>Union[List[float], float]</code> <p>Initial learning rate for each group of parameters.</p> <code>0.001</code> Source code in <code>thunder/policy.py</code> <pre><code>def __init__(self, mapping, lr_init: Union[List[float], float] = 1e-3):\n\"\"\"\n    Base class for policy with mapping. Mapping can be a dict or a function\n    (it should also be a list of latter types in case of multiple param groups).\n    Mapping is the binding between epoch or step number and learning rate value.\n    Parameters\n    ----------\n    mapping\n        Binding of epoch or step number and learning rate.\n    lr_init: Union[List[float], float]]\n        Initial learning rate for each group of parameters.\n    \"\"\"\nself.current_mapping = None\nself.mapping = mapping\nself.current_lr_init = None\nself.lr_init = lr_init\nsuper().__init__()\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.current_mapping","title":"current_mapping  <code>instance-attribute</code>","text":"<pre><code>current_mapping = None\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.mapping","title":"mapping  <code>instance-attribute</code>","text":"<pre><code>mapping = mapping\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.current_lr_init","title":"current_lr_init  <code>instance-attribute</code>","text":"<pre><code>current_lr_init = None\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.lr_init","title":"lr_init  <code>instance-attribute</code>","text":"<pre><code>lr_init = lr_init\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.set_optimizer","title":"set_optimizer","text":"<pre><code>set_optimizer(optimizer: Optimizer) -&gt; None\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def set_optimizer(self, optimizer: Optimizer) -&gt; None:\nself.current_mapping = self.mapping\nif isinstance(self.mapping, dict) or callable(self.mapping):\nself.current_mapping = [deepcopy(self.mapping) for _ in optimizer.param_groups]\nself.current_lr_init = self.lr_init\nif isinstance(self.lr_init, (float, int)):\nself.current_lr_init = [self.lr_init for _ in optimizer.param_groups]\nif len(self.current_mapping) != len(optimizer.param_groups):\nraise ValueError(f\"Got {len(self.current_mapping)} mappings and {len(optimizer.param_groups)} param groups\")\nif len(self.current_lr_init) != len(optimizer.param_groups):\nraise ValueError(f\"Got {len(self.current_lr_init)} lr_init and {len(optimizer.param_groups)} param groups\")\nfor lr_init, param_group in zip(self.current_lr_init, optimizer.param_groups):\nparam_group[\"lr\"] = lr_init\nsuper().set_optimizer(optimizer)\n</code></pre>"},{"location":"policy/lr_schedulers/#thunder.policy.MappingPolicy.__repr__","title":"__repr__","text":"<pre><code>__repr__() -&gt; str\n</code></pre> Source code in <code>thunder/policy.py</code> <pre><code>def __repr__(self) -&gt; str:\nmapping = self.current_mapping if self.current_mapping else self.mapping\nlr_init = self.current_lr_init if self.current_lr_init is not None else self.lr_init\nreturn f\"{self.__class__.__name__}({mapping=}, {lr_init=})\"\n</code></pre>"}]}